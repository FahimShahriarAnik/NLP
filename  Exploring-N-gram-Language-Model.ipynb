{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FahimShahriarAnik/NLP/blob/main/%20Exploring-N-gram-Language-Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "### N-gram Language Model\n",
        "In this assignment, you will build several n-gram models. For submission, you will need to first ***make a copy of this notebook*** (File-> save a copy to drive). Next, fill out each of the functions for each task. Make sure to run each cell and check if the output is correct or not. Finally, submit a pdf (File->print). Note, you should not use any library for the code other than the ones already imported."
      ],
      "metadata": {
        "id": "DofX4RZumFrm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBGBXSwDljoX",
        "outputId": "056964cf-5a0b-4ddc-f4bf-bc6164b5f2cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[',', 'i', 'can', 'mend', 'you', 'mur', '.', 'what', 'mean', \"'\"]\n"
          ]
        }
      ],
      "source": [
        "# import and download corpus\n",
        "import nltk\n",
        "from nltk.corpus import gutenberg\n",
        "import numpy as np\n",
        "\n",
        "nltk.download('gutenberg')\n",
        "nltk.download('punkt')\n",
        "\n",
        "# getting a list of words from this book\n",
        "caesar = gutenberg.words('shakespeare-caesar.txt')\n",
        "# convert all to lower case\n",
        "caesar = [l.lower() for l in caesar]\n",
        "# print first ten words here\n",
        "print(caesar[210:220])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Task 1: Write functions to count unique occurences and co-occurence for words next to each other only. (Points: 5)\n",
        "\n"
      ],
      "metadata": {
        "id": "UIzusZc_m8pB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def count_unique_occurences(list_of_words):\n",
        "  list_of_lists = []\n",
        "  # list_of_lists should be a lit of tuples (a, b) where a is the word and b is the count\n",
        "  # replace the list here with your code\n",
        "  #list_of_lists = [('julius', 5), ('ceasur', 3)]\n",
        "\n",
        "  word_count = {}\n",
        "  for word in list_of_words:\n",
        "      if word in word_count:\n",
        "          word_count[word] += 1\n",
        "      else:\n",
        "          word_count[word] = 1\n",
        "\n",
        "  # Convert the dictionary to a list of tuples\n",
        "  list_of_lists = list(word_count.items())\n",
        "\n",
        "  return list_of_lists\n",
        "#count_unique_occurences(caesar)"
      ],
      "metadata": {
        "id": "PZXUPWzIl_mR",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_co_occurences(list_of_words):\n",
        "  LST_DICT = []\n",
        "  # LST_DICT should be a lit of tuples (a, b) where a is the word1:word2 and b is the count\n",
        "  # replace the list here with your code\n",
        "  #LST_DICT = [('julius:ceasur', 5), ('i:am', 3)]\n",
        "  co_occurrence_count = {}\n",
        "  for i in range(len(list_of_words) - 1):\n",
        "      pair = f\"{list_of_words[i]}:{list_of_words[i + 1]}\"\n",
        "      if pair in co_occurrence_count:\n",
        "          co_occurrence_count[pair] += 1\n",
        "      else:\n",
        "          co_occurrence_count[pair] = 1\n",
        "\n",
        "  # Convert the dictionary to a list of tuples\n",
        "  LST_DICT = list(co_occurrence_count.items())\n",
        "\n",
        "  return LST_DICT"
      ],
      "metadata": {
        "id": "XlEg1y05mZrA",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print first five occurences\n",
        "occurences = count_unique_occurences(caesar)\n",
        "_ = [print(l) for l in occurences[:5]]\n",
        "\n",
        "print(len(occurences))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hPzSfWLaqWQ2",
        "outputId": "42961503-10a8-429b-b439-07a64fd35675"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('[', 3)\n",
            "('the', 579)\n",
            "('tragedie', 2)\n",
            "('of', 354)\n",
            "('julius', 1)\n",
            "3032\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print first five co-occurences\n",
        "co_occurences = count_co_occurences(caesar)\n",
        "_ = [print(l) for l in co_occurences[:5]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fkk3cmSlrKZ3",
        "outputId": "7bb8feb3-b297-4dd0-c08e-f6639f391321"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('[:the', 1)\n",
            "('the:tragedie', 2)\n",
            "('tragedie:of', 2)\n",
            "('of:julius', 1)\n",
            "('julius:caesar', 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Task 2: write functions to compute unigram and bigram proability (Points: 5)"
      ],
      "metadata": {
        "id": "Pm2t1UTJpzbe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def occurences_probability(list_of_counts):\n",
        "  list_of_dicts = []\n",
        "  for word, count in list_of_counts:\n",
        "    list_of_dicts.append((word, str(count/len(list_of_counts))))\n",
        "\n",
        "  return list_of_dicts"
      ],
      "metadata": {
        "id": "Z21zVmYvpiCt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def occurences_of_one_word(word):\n",
        "  for w, count in occurences:\n",
        "    if w == word:\n",
        "      return count\n",
        "  return 1\n",
        "\n",
        "def co_occurences_probability(list_of_counts):\n",
        "  list_of_dicts = []\n",
        "\n",
        "  for word, count in list_of_counts:\n",
        "    words= word.split(\":\")\n",
        "    list_of_dicts.append((word, str((count+1)/ (occurences_of_one_word(words[1]) + len(list_of_counts) ) ))) # implemented the add-1 estimate formula\n",
        "\n",
        "  return list_of_dicts\n",
        "\n",
        "#co_occurences_probability(co_occurences)"
      ],
      "metadata": {
        "id": "AlX0JmKcsc1F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print first five occurences\n",
        "occ_prob = occurences_probability(occurences)\n",
        "_ = [print(l) for l in occ_prob[:5]]\n",
        "print(len(occ_prob))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfGrNSsrswbt",
        "outputId": "9b7927a3-6883-4284-ff14-2ee97ac07bf6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('[', '0.0009894459102902375')\n",
            "('the', '0.19096306068601582')\n",
            "('tragedie', '0.0006596306068601583')\n",
            "('of', '0.11675461741424802')\n",
            "('julius', '0.00032981530343007914')\n",
            "3032\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print first five co-occurences probabilities\n",
        "co_occ_prob = co_occurences_probability(co_occurences)\n",
        "_ = [print(l) for l in co_occ_prob[:5]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOdeArJStM_7",
        "outputId": "349d3f93-a7e4-4153-f515-4be1a804436a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('[:the', '0.00013410218586562962')\n",
            "('the:tragedie', '0.0002092487968194183')\n",
            "('tragedie:of', '0.0002042344611614133')\n",
            "('of:julius', '0.00013950892857142856')\n",
            "('julius:caesar', '0.0001376936316695353')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Task 3: Find probability of a sentence using unigram and bigram model (points 5)"
      ],
      "metadata": {
        "id": "P3DuNj8Zt-DR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def unigram_sent_probability(sent, prob_list):\n",
        "  prob = 0.1\n",
        "  words = sent.split()\n",
        "  for word in words:\n",
        "    for w, p in prob_list:\n",
        "      if w == word:\n",
        "        prob *= float(p)\n",
        "\n",
        "  return prob"
      ],
      "metadata": {
        "id": "EPIG3Ecnt5oI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bigram_sent_probability(sent, prob_list):\n",
        "  prob = 0.2\n",
        "  # compute probability\n",
        "  # here sent will be a string that you will have to split\n",
        "  words = sent.split()\n",
        "  for i in range(len(words) - 1):\n",
        "    for word, p in prob_list:\n",
        "      pair = f\"{words[i]}:{words[i + 1]}\"\n",
        "      if word == pair:\n",
        "        prob *= float(p)\n",
        "\n",
        "  return prob"
      ],
      "metadata": {
        "id": "ke0b3-XPvMCF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent = \"i can mend you\"\n",
        "u_prob = unigram_sent_probability(sent, occ_prob)\n",
        "b_prob = bigram_sent_probability(sent, co_occ_prob)\n",
        "print(\"Unigram probability for\", sent, \"is:\", u_prob)\n",
        "print(\"Bigram probability for\", sent, \"is:\", b_prob)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dT8pKviPvbZj",
        "outputId": "c01d11fb-5922-4026-9d13-33180cf4ca86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unigram probability for i can mend you is: 9.370672832607475e-09\n",
            "Bigram probability for i can mend you is: 2.375836078964408e-12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Task 4: Predict the most probable next word (Points 5)"
      ],
      "metadata": {
        "id": "y1ASRMOXxA4M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def uni_predict_next_words(sent, prob_list, n=1):\n",
        "  words = sent.split()\n",
        "  for w,p in prob_list:\n",
        "    if w in words:\n",
        "      prob_list.remove((w,p))\n",
        "\n",
        "\n",
        "  output_words = []\n",
        "  ## calculating next best prob word, appending it to returning list and removing it from prob_list\n",
        "  for i in range(n):\n",
        "    max_p = -1\n",
        "    for word, p in prob_list:\n",
        "      if float(p) > max_p:\n",
        "        max_p = float(p)\n",
        "        max_p_word = word\n",
        "        #print(max_p_word)\n",
        "    output_words.append(max_p_word)\n",
        "    prob_list.remove((max_p_word, str(max_p)))\n",
        "\n",
        "  return output_words"
      ],
      "metadata": {
        "id": "JVqP90jOwZXa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bi_predict_next_words(sent, prob_list, n=1):\n",
        "  # go through all combination of words and find the next n words with highest probability and return the list\n",
        "  # replace this with your code\n",
        "  #word = ['I']\n",
        "\n",
        "  output_words = []\n",
        "  words = sent.split()\n",
        "\n",
        "  last_word = words[len(words)-1]\n",
        "\n",
        "  for i in range(n):\n",
        "    max_p = -1\n",
        "    next_word = ''\n",
        "\n",
        "    for word, p in prob_list:\n",
        "      if word.split(\":\")[0] == last_word:\n",
        "        if float(p) > max_p:\n",
        "          max_p = float(p)\n",
        "          max_p_word = word\n",
        "          next_word = word.split(\":\")[1]\n",
        "    output_words.append(next_word)\n",
        "    last_word = next_word\n",
        "    prob_list.remove((max_p_word, str(max_p)))\n",
        "\n",
        "  return output_words"
      ],
      "metadata": {
        "id": "bFvJ93ns04E6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "u_next_words = uni_predict_next_words(sent, occ_prob, n=10)\n",
        "b_next_words = bi_predict_next_words(sent, co_occ_prob, n=10)\n",
        "print(\"Unigram-based next best word for\", sent, \"is:\", u_next_words)\n",
        "print(\"Bigram-based next best word for\", sent, \"is:\", b_next_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CraaOB9gykmt",
        "outputId": "b78df237-38d1-4482-9f5b-19a964b4e955"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unigram-based next best word for i can mend you is: [',', '.', 'and', 'the', ':', 'to', \"'\", 'of', '?', 'that']\n",
            "Bigram-based next best word for i can mend you is: ['are', 'not', ',', 'and', 'i', 'will', ',', 'i', 'am', 'i']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Task 5: Interpolated Probability. (Points 5)"
      ],
      "metadata": {
        "id": "b2nCDjo91ZAa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def linearly_interpolated_sent_probability(sent, lam1, prob_list_u, lam2, prob_list_b):\n",
        "  # here instead of uni or bigram, you will use linear interpolation to find the probability of the sentence\n",
        "  # lambda values are lam1 for unigram and lam2 for bigram\n",
        "  # replace this line with your code\n",
        "  prob = 0.0\n",
        "  prob += lam1 * unigram_sent_probability(sent, prob_list_u)\n",
        "  prob += lam2 * bigram_sent_probability(sent, prob_list_b)\n",
        "\n",
        "  return prob"
      ],
      "metadata": {
        "id": "tlszF7V0znkP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# lets see how probability changes with lambda values\n",
        "for i in range(1,10):\n",
        "  l_prob = linearly_interpolated_sent_probability(sent, i/10, occ_prob, 1-(i)/10, co_occ_prob)\n",
        "  print(\"With lamda \", i/10, \"%.1f\" % (1-(i)/10), \"interpolated probability for\", sent, \"is:\", l_prob)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "672orwHI2uew",
        "outputId": "2489dc7c-c113-480f-c564-7309bbde071a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "With lamda  0.1 0.9 interpolated probability for i can mend you is: 6.596308206854054e-06\n",
            "With lamda  0.2 0.8 interpolated probability for i can mend you is: 1.319261403787203e-05\n",
            "With lamda  0.3 0.7 interpolated probability for i can mend you is: 1.9788919868890004e-05\n",
            "With lamda  0.4 0.6 interpolated probability for i can mend you is: 2.638522569990798e-05\n",
            "With lamda  0.5 0.5 interpolated probability for i can mend you is: 3.298153153092595e-05\n",
            "With lamda  0.6 0.4 interpolated probability for i can mend you is: 3.957783736194393e-05\n",
            "With lamda  0.7 0.3 interpolated probability for i can mend you is: 4.61741431929619e-05\n",
            "With lamda  0.8 0.2 interpolated probability for i can mend you is: 5.277044902397988e-05\n",
            "With lamda  0.9 0.1 interpolated probability for i can mend you is: 5.936675485499785e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iEv9atKO33tJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}